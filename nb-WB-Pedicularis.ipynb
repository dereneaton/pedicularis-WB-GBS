{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly and analysis of *Pedicularis* PE-GBS data set\n",
    "\n",
    "A library for 48 samples was prepared following the protocol described in Escudero et al. 2013 with the PstI restriction enzyme, followed by PCR amplification of primer ligated fragments. The library prep lacked a size selection step, which we discuss in the methods below.  The library was sequenced on one lane of an Illumina HiSeq 2000 yielding 378,809,976 reads in lane 1, and 375,813,513 reads in lane 2, for a total of ~755M reads.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook\n",
    "This notebook provides a fully reproducible workflow to assemble and analyze the Yu-Eaton-Ree 2012 Pedicularis GBS data set, and to save the results into a github repo with this notebook [see git repo here](https://github.com/dereneaton/pedicularis-WB-GBS). Starting from the raw data files, we denovo assemble the data in *ipyrad*, which involves demultiplexing and filtering reads, and then clustering within and between samples to identify homology, followed by final filtering and formating to create output files. Analysis of the resulting files is shown in separate notebooks, again available in the [git repo](https://github.com/dereneaton/pedicularis-WB-GBS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/de243/pedicularis-WB-GBS\n",
      "/fastscratch/de243/\n",
      "https://github.com/dereneaton/pedicularis-WB-GBS.git\n"
     ]
    }
   ],
   "source": [
    "## show my local dir (where this notebook is located)\n",
    "! pwd\n",
    "\n",
    "## show the scratch dir (where data will be written)\n",
    "! echo /fastscratch/de243/\n",
    "\n",
    "## show that this dir has a git repo (.git file mapping to the address shown)\n",
    "## this allows me to push updates to this notebook directly to github, \n",
    "## and to easily share the notebook with collaborators and as a final document.\n",
    "! git config --get remote.origin.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ipyrad and other common modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyrad v.0.4.3\n",
      "ipyparallel v.5.0.1\n",
      "numpy v.1.11.0\n"
     ]
    }
   ],
   "source": [
    "## all necessary software can be installed by uncommenting the command below\n",
    "# conda install -c ipyrad ipyrad -y\n",
    "\n",
    "## import basic modules and ipyrad and print version\n",
    "import os\n",
    "import socket\n",
    "import glob\n",
    "import subprocess as sps\n",
    "import numpy as np\n",
    "import ipyparallel as ipp\n",
    "import ipyrad as ip\n",
    "\n",
    "print \"ipyrad v.{}\".format(ip.__version__)\n",
    "print \"ipyparallel v.{}\".format(ipp.__version__)\n",
    "print \"numpy v.{}\".format(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cluster\n",
    "This notebook was run connected to 32 cores on 4 nodes of the Louise HPC cluster at Yale. SSH Tunneling was set up following this [tutorial](http://ipyrad.readthedocs.io/HPC_Tunnel.html) to launch an *ipcluster* instance, which we use below to connect ipyrad to the cluster. Here I will create a view to the connected engines using the ipyparallel module, and confirm we are connected to all cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  host compute node: [8 cores] on compute-24-14.local\n",
      "  host compute node: [16 cores] on compute-22-10.local\n",
      "  host compute node: [8 cores] on compute-20-15.local\n"
     ]
    }
   ],
   "source": [
    "## open a view to the client\n",
    "ipyclient = ipp.Client()\n",
    "\n",
    "## confirm we are connected to 4 8-core nodes\n",
    "hosts = ipyclient[:].apply_sync(socket.gethostname)\n",
    "for hostname in set(hosts):\n",
    "    print(\"  host compute node: [{} cores] on {}\"\\\n",
    "          .format(hosts.count(hostname), hostname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory = /fastscratch/de243/WB-PED\n"
     ]
    }
   ],
   "source": [
    "## create a new working directory in HPC scratch dir\n",
    "WORK = \"/fastscratch/de243/WB-PED\"\n",
    "if not os.path.exists(WORK):\n",
    "    os.mkdir(WORK)\n",
    "\n",
    "## print it\n",
    "print \"working directory = {}\".format(WORK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The raw data\n",
    "The raw R1 and R2 data are each split into 59 gzipped files approximately 300MB in size. The barcodes file maps sample names to barcodes that are contained inline in the R1 sequences, and are 4-8bp in length. The barcodes are printed a little further below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Locations of the raw data stored temporarily on Yale's Louise HPC cluster\n",
    "## Data are also stored more permanently on local computer tinus at Yale\n",
    "RAWREADS = \"/fastscratch/de243/TMP_RAWS/*.fastq.gz\"\n",
    "BARCODES = \"/fastscratch/de243/TMP_RAWS/WB-PED_barcodes.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastqc quality check\n",
    "\n",
    "I ran the program *fastQC* on the raw data files to do a quality check, the results of which (will be / are) available here [fastqc_dir](https://github.com/dereneaton/pedicularis-WB-GBS/blob/master/fastqc). Overall, quality scores were not terrible, but also not great, however, our biggest problem was very high adapter contamination. We will filter this out using the program *cutadapt* implemented in step2 of *ipyrad*, and discussed further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 118/118 tasks finished after  153 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## uncomment this to install fastqc with conda\n",
    "#conda install -c bioconda fastqc -q \n",
    "\n",
    "## create a tmp directory for fastqc outfiles (./tmp_fastqc)\n",
    "QUALDIR = os.path.join(os.path.realpath(os.curdir), \"tmp_fastqc\")\n",
    "if not os.path.exists(QUALDIR):\n",
    "    os.mkdir(QUALDIR)\n",
    "    \n",
    "## run fastqc on all raw data files and write outputs to fastqc tmpdir.\n",
    "## This is parallelized by load-balancing with ipyclient\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "for rawfile in glob.glob(RAWREADS):\n",
    "    cmd = ['fastqc', rawfile, '--outdir', QUALDIR, '-t', '1', '-q']\n",
    "    lbview.apply_async(sps.check_output, cmd)\n",
    "    \n",
    "## block until finished and print progress\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/de243/pedicularis-WB-GBS/tmp_fastqc'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUALDIR = os.path.join(os.path.realpath(os.curdir), \"tmp_fastqc\")\n",
    "QUALDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: '/fastscratch/de243/WB-PED/tmp_fastqc/lane2_NoIndex_L002_R1_001_fastqc.html' is outside repository\n",
      "# On branch master\n",
      "# Untracked files:\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\n",
      "#\n",
      "#\t.ipynb_checkpoints/\n",
      "#\tipyrad_log.txt\n",
      "#\tnb-WB-Pedicularis.ipynb\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "error: The requested URL returned error: 403 Forbidden while accessing https://github.com/dereneaton/pedicularis-WB-GBS.git/info/refs\n",
      "\n",
      "fatal: HTTP request failed\n"
     ]
    }
   ],
   "source": [
    "## update fastqc html results and this notebook\n",
    "! git add $QUALDIR/*.html nb-WB-Pedicularis.ipynb\n",
    "! git commit -m \"fastq html results uploaded\"\n",
    "! git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: '/fastscratch/de243/WB-PED/fastqc/lane2_NoIndex_L002_R1_001_fastqc.html' is outside repository\n",
      "# On branch master\n",
      "# Untracked files:\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\n",
      "#\n",
      "#\t.ipynb_checkpoints/\n",
      "#\tipyrad_log.txt\n",
      "#\tnb-WB-Pedicularis.ipynb\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "error: The requested URL returned error: 403 Forbidden while accessing https://github.com/dereneaton/pedicularis-WB-GBS.git/info/refs\n",
      "\n",
      "fatal: HTTP request failed\n"
     ]
    }
   ],
   "source": [
    "## cleanup tmpdir\n",
    "! rm -r $QUALDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create demultiplexed files for each Sample in *ipyrad*\n",
    "We set the location to the data and barcodes info for each object, and set the max barcode mismatch parameter to zero (strict), allowing no mismatches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  New Assembly: WB-PED_demux\n"
     ]
    },
    {
     "ename": "IPyradError",
     "evalue": "    Error setting parameter 'barcodes_path'\n    list index out of range\n    You entered: /home2/de243/RADSEQ_RAWS/WB-PED/WB-PED_barcodes.txt\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIPyradError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-77fe55b088fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdemux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"project_dir\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWORK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"demux_reads\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdemux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw_fastq_path\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRAWREADS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdemux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"barcodes_path\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBARCODES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdemux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_barcode_mismatch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home2/de243/ipyrad-git/ipyrad/core/assembly.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, param, newvalue)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             raise IPyradWarningExit(BAD_PARAMETER\\\n\u001b[1;32m--> 681\u001b[1;33m                                     .format(param, inst, newvalue))\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home2/de243/ipyrad-git/ipyrad/assemble/util.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mipyrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__interactive__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIPyradError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mSystemExit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIPyradError\u001b[0m:     Error setting parameter 'barcodes_path'\n    list index out of range\n    You entered: /home2/de243/RADSEQ_RAWS/WB-PED/WB-PED_barcodes.txt\n    "
     ]
    }
   ],
   "source": [
    "## create an object to demultiplex each lane\n",
    "demux = ip.Assembly(\"WB-PED_demux\")\n",
    "\n",
    "## set basic derep parameters for the two objects\n",
    "demux.set_params(\"project_dir\", os.path.join(WORK, \"demux_reads\"))\n",
    "demux.set_params(\"raw_fastq_path\", RAWREADS)\n",
    "demux.set_params(\"barcodes_path\", BARCODES)\n",
    "demux.set_params(\"max_barcode_mismatch\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
